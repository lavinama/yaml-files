{
    "agent": {
        "__class__": "<class 'rl_agents.agents.multi_agent_deep_deterministic_policy_gradient.pytorch.MADDPGAgent'>",
        "batch_size": 100,
        "device": "cuda:best",
        "double": true,
        "exploration": {
            "final_temperature": 0.05,
            "method": "EpsilonGreedy",
            "tau": 150000,
            "temperature": 1.0
        },
        "gamma": 0.95,
        "loss_function": "l2",
        "memory_capacity": 50000,
        "models": {
            "actor": {
                "base_net": {
                    "attention_layer": {
                        "feature_size": 64,
                        "heads": 1,
                        "type": "EgoAttention"
                    },
                    "embedding_layer": {
                        "in": 9,
                        "layers": [
                            64,
                            64
                        ],
                        "reshape": false,
                        "type": "MultiLayerPerceptron"
                    },
                    "layers": [
                        128,
                        128
                    ],
                    "others_embedding_layer": {
                        "in": 9,
                        "layers": [
                            64,
                            64
                        ],
                        "reshape": false,
                        "type": "MultiLayerPerceptron"
                    },
                    "out": null,
                    "output_layer": {
                        "layers": [
                            64,
                            64
                        ],
                        "reshape": false,
                        "type": "MultiLayerPerceptron"
                    },
                    "self_attention_layer": null,
                    "type": "EgoAttentionNetwork"
                },
                "in": 144,
                "out": 3,
                "out_activation": "SOFTMAX",
                "type": "ActorNetwork"
            },
            "critic": {
                "base_net": {
                    "attention_layer": {
                        "feature_size": 64,
                        "heads": 1,
                        "type": "EgoAttention"
                    },
                    "embedding_layer": {
                        "in": 12,
                        "layers": [
                            64,
                            64
                        ],
                        "reshape": false,
                        "type": "MultiLayerPerceptron"
                    },
                    "layers": [
                        128,
                        128,
                        128
                    ],
                    "others_embedding_layer": {
                        "in": 12,
                        "layers": [
                            64,
                            64
                        ],
                        "reshape": false,
                        "type": "MultiLayerPerceptron"
                    },
                    "out": null,
                    "output_layer": {
                        "layers": [
                            64,
                            64
                        ],
                        "reshape": false,
                        "type": "MultiLayerPerceptron"
                    },
                    "self_attention_layer": null,
                    "type": "EgoAttentionNetwork"
                },
                "in": 9,
                "n_actions": 3,
                "n_agents": 4,
                "out": 3,
                "type": "CriticNetwork"
            }
        },
        "n_agents": 4,
        "n_steps": 1,
        "optimizer": {
            "k": 5,
            "lr": 0.0005,
            "type": "ADAM",
            "weight_decay": 0
        },
        "target_update": 512,
        "tau": 0.01
    },
    "env": {
        "__class__": "<class 'gym.wrappers.order_enforcing.OrderEnforcing'>",
        "action": {
            "action_config": {
                "lateral": false,
                "longitudinal": true,
                "target_speeds": [
                    -3,
                    0,
                    4.5,
                    9
                ],
                "type": "DiscreteMetaAction"
            },
            "type": "MultiAgentAction"
        },
        "arrived_reward": 1,
        "centering_position": [
            0.5,
            0.5
        ],
        "check_reg_road": false,
        "collision_reward": -5,
        "controlled_vehicles": 4,
        "destination": "o1",
        "duration": 13,
        "failmaker_advrl": false,
        "hash_intersection": false,
        "high_speed_reward": 1,
        "id": "intersection-multi-agent-adv-v0",
        "import_module": "highway_env",
        "initial_vehicle_count": 0,
        "manual_control": false,
        "normalize_reward": false,
        "observation": {
            "observation_config": {
                "absolute": true,
                "features": [
                    "presence",
                    "x",
                    "y",
                    "vx",
                    "vy",
                    "cos_h",
                    "sin_h",
                    "cos_d",
                    "sin_d"
                ],
                "features_range": {
                    "vx": [
                        -20,
                        20
                    ],
                    "vy": [
                        -20,
                        20
                    ],
                    "x": [
                        -100,
                        100
                    ],
                    "y": [
                        -100,
                        100
                    ]
                },
                "order": "shuffled",
                "type": "Kinematics",
                "vehicles_count": 16
            },
            "type": "MultiAgentObservation"
        },
        "offroad_terminal": false,
        "offscreen_rendering": false,
        "other_vehicles_type": "highway_env.vehicle.behavior.IDMVehicle",
        "policy_frequency": 1,
        "real_time_rendering": false,
        "render_agent": true,
        "reward_speed_range": [
            7.0,
            9.0
        ],
        "rule_break_reward": 0,
        "scaling": 7.15,
        "scaling_factor": 1,
        "screen_height": 600,
        "screen_width": 600,
        "show_trajectories": false,
        "simulation_frequency": 15,
        "spawn_probability": 0,
        "speed_to_reward": 3.5,
        "zero_sum_rewards": false
    }
}